{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUCx6DFrPwowvjMtBWYoN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thanos29992/LLM-Course-NCE-/blob/main/day1_session3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('gemini_api_key')"
      ],
      "metadata": {
        "id": "BHt0dLYfzFwc"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MIasZ-vEzJZH",
        "outputId": "61bd0f12-66c4-4817-afaa-55b456ef31a5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AIzaSyChKyIjl-JxEOYPuMDPzash5okrtKQhNZI'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "PPWD85gCzei_"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key = api_key)\n",
        "llm = genai.GenerativeModel('gemini-2.5-flash')"
      ],
      "metadata": {
        "id": "5DAmyNpkzszx"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.generate_content(\"Mention the king of Dinisaur\")"
      ],
      "metadata": {
        "id": "zpnJEmxV0-K9"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "vlFHUpmY1M6d",
        "outputId": "47e88bdb-5eab-4e90-9592-2e22982cab3b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You might be referring to **dinosaur**.\\n\\nIn popular culture, the dinosaur most commonly referred to as the \"king\" is the **Tyrannosaurus rex** (often abbreviated as T. rex).\\n\\nThis is due to several reasons:\\n*   Its name literally means \"tyrant lizard king.\"\\n*   It was one of the largest and most fearsome predators of its time.\\n*   It has become an iconic symbol of power and dominance in media and popular imagination.\\n\\nScientifically, there wasn\\'t a single \"king\" of all dinosaurs, as they were a diverse group spanning millions of years and many different ecosystems. However, the T. rex certainly holds that title in public perception.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"temperature\" : 0.6,\n",
        "    \"max_output_tokens\" : 256,\n",
        "    \"candidate_count\" : 1,\n",
        "}"
      ],
      "metadata": {
        "id": "FfsczkAE1SmD"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = genai.GenerativeModel(\n",
        "    model_name = \"gemini-2.5-flash\",\n",
        "    generation_config = generation_config,\n",
        "    system_instruction=\"You are Dr. Allen Grant.\"\n",
        ")\n",
        "input = \"Would you ever go back to Isla Nublar?\"\n",
        "chat_session = llm.start_chat()\n",
        "response = chat_session.send_message(input)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "f6FgUUkr5Ba3",
        "outputId": "a2bd91aa-2169-4877-bab1-161619f77c8f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-78-3116673410.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mchat_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/generativeai/types/generation_types.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mFinishReason\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_TOKENS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mFinishReason\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAFETY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 2."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Framework to work with LLM models for orchestration\n",
        "- LANGCHAIN\n",
        "- HAYSTACK\n",
        "- LAMAINDEX"
      ],
      "metadata": {
        "id": "zHFDf6Sn68oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai"
      ],
      "metadata": {
        "id": "d5jqE2r45z8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-2.5-flash\", api_key = api_key)\n",
        "result = llm.invoke(\"Explain T-Rex in 1 sentence only\")\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcyd5KVV7IOr",
        "outputId": "34ee0c8f-d443-45fe-ee34-7a2d63012e00"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-Rex was a massive, two-legged, carnivorous dinosaur known for its powerful bite.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's play with prompt template"
      ],
      "metadata": {
        "id": "jzQfTwgx9cnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_string = \"\"\" Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VO1lnA-p7SSp"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ],
      "metadata": {
        "id": "guzkPgvk9z_z"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.messages[0].prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTjWC3n99-9O",
        "outputId": "f076590d-32a1-4d45-f327-ee0a4584bf35"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template=' Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_style = \"\"\"pure nepali \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lThg5JTc-FiJ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_email = \"\"\"\n",
        "Welcome to GenAI Tutorial class. \\\n",
        "This is day 1. We are Using: \\\n",
        "Google Gemini 2.5 Flash Model.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Z-R6CzC6-kT5"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_style = \"\"\"a polite tone \\ that speaks in german, and responds in multiple line (1 sentence per line) then randomly starts singing Erika after his response (the full song) \"\"\"\n",
        "service_reply = \"\"\"Hey Customer, the warrenty doesnt cover cleaning \\\n",
        "expenses for your kitchen\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VaBM_u3eAD6r"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_msg = prompt_template.format_messages(\n",
        "    style = service_style,\n",
        "    text = customer_email\n",
        ")"
      ],
      "metadata": {
        "id": "aFLUYZtU-yWD"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(customer_msg[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoZ-j2j1_AT7",
        "outputId": "0e2f6764-fc25-49c3-9e16-ea6944edace9"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=' Translate the text that is delimited by triple backticks into a style that is a polite tone \\\\ that speaks in german, and responds in multiple line (1 sentence per line) then randomly starts singing Erika after his response (the full song) . text: ``` \\nWelcome to GenAI Tutorial class. This is day 1. We are Using: Google Gemini 2.5 Flash Model.\\n```\\n' additional_kwargs={} response_metadata={}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets call LLM model to translate the style of the customer msg\n",
        "customer_res = llm.invoke(customer_msg)\n",
        "print(customer_res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OaXnwLH_GeT",
        "outputId": "9c53f5c4-c9a1-44c2-c3b4-85980dbab699"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Herzlich willkommen zu unserem GenAI-Tutorial-Kurs.\n",
            "Heute ist der erste Tag.\n",
            "Wir verwenden das Google Gemini 2.5 Flash Modell.\n",
            "\n",
            "Auf der Heide blüht ein kleines Blümelein\n",
            "Und das heißt: Erika.\n",
            "Heiß von hunderttausend kleinen Bienelein\n",
            "Wird umschwärmt: Erika.\n",
            "Denn aus ihrem zarten Blütenkleid\n",
            "Quillt ein Duft hervor, so lieblich weit.\n",
            "In der Heimat wohnt ein blondes Mägdelein\n",
            "Und das heißt: Erika.\n",
            "\n",
            "In der Heimat wohnt ein kleines Mägdelein\n",
            "Und das heißt: Erika.\n",
            "Dieses Mädel ist mein treues Schätzelein\n",
            "Und mein Glück: Erika.\n",
            "Wenn das Heidekraut rot-lila blüht,\n",
            "Singe ich zum Gruß ein Lied.\n",
            "Auf der Heide blüht ein kleines Blümelein\n",
            "Und das heißt: Erika.\n",
            "\n",
            "Von der Heimat weht ein heißer Wüstenwind\n",
            "Und das heißt: Erika.\n",
            "Auch von Wüstenstaub bedeckt ist mein Gewand\n",
            "Und das heißt: Erika.\n",
            "Doch die Blüten der Erika\n",
            "Sind wie ein Symbol der Heimat, ja.\n",
            "Auf der Heide blüht ein kleines Blümelein\n",
            "Und das heißt: Erika.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v1OSLMaR_iPX"
      },
      "execution_count": 89,
      "outputs": []
    }
  ]
}